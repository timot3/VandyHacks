{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timot3/VandyHacks/blob/master/colabs/RCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qygh6WrXnLuV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "4d537d1f-98eb-43b9-b22f-a4eae6ddb8c8"
      },
      "source": [
        "import os\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.26.30.162:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 18174336499162816504),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 13722262632672477084),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10743959276646528317),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 18402627857107181162),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 15218748027090491897),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9450628180967227223),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4051024466101586552),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 6371970268212979658),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9010154581262721462),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 6547912671067298133),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 16372172500608055712)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk6wfeGNxWrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "acfd753f-27a3-48ba-e404-8ca6a79d6b73"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Initializing...\n",
            "Running ops\n",
            "[array([ 0.,  2.,  4.,  6.,  8., 10., 12., 14., 16., 18.], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQgRVrtG0GEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "  BUFFER_SIZE = 150000\n",
        "\n",
        "  BATCH_SIZE_PER_REPLICA = 64\n",
        "  GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA*8\n",
        "\n",
        "  EPOCHS = 50\n",
        "  import os\n",
        "  import pprint\n",
        "  import tensorflow as tf\n",
        "\n",
        "  if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "    print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "  else:\n",
        "    tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    print ('TPU address is', tpu_address)\n",
        "\n",
        "    with tf.Session(tpu_address, config=tf.ConfigProto(\n",
        "        allow_soft_placement=True, log_device_placement=True)) as session:\n",
        "      devices = session.list_devices()\n",
        "      \n",
        "    print('TPU devices:')\n",
        "    pprint.pprint(devices)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ0ffvmXxZOB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d42c8628-7d29-41c4-a368-102c2f876edc"
      },
      "source": [
        "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p761-pyxdAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "65e1dceb-f377-4169-c84c-0293ee4660ff"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def add_op(x, y):\n",
        "  return x + y\n",
        "  \n",
        "x = tf.placeholder(tf.float32, [10,])\n",
        "y = tf.placeholder(tf.float32, [10,])\n",
        "tpu_ops = tf.contrib.tpu.rewrite(go)\n",
        "  \n",
        "session = tf.Session(tpu_address)\n",
        "try:\n",
        "  print('Initializing...')\n",
        "  session.run(tf.contrib.tpu.initialize_system())\n",
        "  print('Running ops')\n",
        "  print(session.run(tpu_ops, {x: np.arange(10), y: np.arange(10)}))\n",
        "finally:\n",
        "  # For now, TPU sessions must be shutdown separately from\n",
        "  # closing the session.\n",
        "  session.run(tf.contrib.tpu.shutdown_system())\n",
        "  session.close()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Plot the model visualization\n",
            "DCGAN_Generator\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:absl:Operation of type Placeholder (dense_1_input) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-68a778da0444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtpu_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tpu/tpu.py\u001b[0m in \u001b[0;36mrewrite\u001b[0;34m(computation, inputs, infeed_queue, device_assignment, name)\u001b[0m\n\u001b[1;32m   1512\u001b[0m       \u001b[0minfeed_queue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfeed_queue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m       \u001b[0mdevice_assignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_assignment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m       name=name)[0]\n\u001b[0m\u001b[1;32m   1515\u001b[0m   \u001b[0;31m# pylint: enable=indexing-exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tpu/tpu.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(computation, inputs, infeed_queue, device_assignment, name, maximum_shapes)\u001b[0m\n\u001b[1;32m    637\u001b[0m       \u001b[0mdevice_assignment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m       maximum_shapes=maximum_shapes)[1]\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tpu/tpu.py\u001b[0m in \u001b[0;36msplit_compile_and_replicate\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    990\u001b[0m       \u001b[0mvscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_custom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcomputation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m       \u001b[0mvscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_use_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_use_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-15bcbb644138>\u001b[0m in \u001b[0;36mgo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DCGAN_Generator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBuildGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'DCGAN_Generator.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-15bcbb644138>\u001b[0m in \u001b[0;36mBuildGenerator\u001b[0;34m(summary, resnet, bn_momentum, bn_epsilon, name, plot)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 425\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    893\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             self.bias = self.add_weight(shape=(self.units,),\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    244\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                             constraint=constraint)\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight_regularizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m   def _variable_v2_call(cls,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m                         shape=None):\n\u001b[1;32m    196\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2501\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2502\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2503\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2504\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2505\u001b[0m     return variables.RefVariable(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1404\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m   def _init_from_args(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1558\u001b[0m               \u001b[0;34m\"construct, such as a loop or conditional. When creating a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m               \u001b[0;34m\"variable inside a loop or conditional, use a lambda as the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m               \"initializer.\" % name)\n\u001b[0m\u001b[1;32m   1561\u001b[0m         \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Initializer for variable dense_1/kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2FLxt092hgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "f3bd9e6d-e004-4ba3-837f-e8da62fc57bb"
      },
      "source": [
        "tpu_ops = tf.contrib.tpu.batch_parallel(go, num_shards=8)\n",
        "tpu_ops2 = tf.contrib.tpu.batch_parallel(model, num_shards=8)\n",
        "tpu_ops2 = tf.contrib.tpu.batch_parallel(model, num_shards=8)\n",
        "session = tf.Session(tpu_address)\n",
        "try:\n",
        "  print('Warming up...')\n",
        "  session.run(tf.contrib.tpu.initialize_system())\n",
        "  session.run(tpu_ops)\n",
        "  print('Profiling')\n",
        "  start = time.time()\n",
        "  session.run(tpu_ops)\n",
        "  end = time.time()\n",
        "  elapsed = end - start\n",
        "  print(elapsed, 'TFlops: {:.2f}'.format(1e-12 * 8 * COUNT * 2*N*N*N / elapsed))\n",
        "finally:\n",
        "  session.run(tf.contrib.tpu.shutdown_system())\n",
        "  session.close()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:absl:Operation of type Placeholder (dense_2_input) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Plot the model visualization\n",
            "DCGAN_Generator\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-decb3537f243>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtpu_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtpu_ops2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Warming up...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tpu/tpu.py\u001b[0m in \u001b[0;36mbatch_parallel\u001b[0;34m(computation, inputs, num_shards, infeed_queue, device_assignment, name)\u001b[0m\n\u001b[1;32m   1459\u001b[0m       \u001b[0minfeed_queue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfeed_queue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m       \u001b[0mdevice_assignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_assignment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tpu/tpu.py\u001b[0m in \u001b[0;36mshard\u001b[0;34m(computation, inputs, num_shards, input_shard_axes, outputs_from_all_shards, output_shard_axes, infeed_queue, device_assignment, name)\u001b[0m\n\u001b[1;32m   1402\u001b[0m       \u001b[0minfeed_queue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfeed_queue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m       \u001b[0mdevice_assignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_assignment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1404\u001b[0;31m       name=name)[1]\n\u001b[0m\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tpu/tpu.py\u001b[0m in \u001b[0;36msplit_compile_and_shard\u001b[0;34m(computation, inputs, num_shards, input_shard_axes, outputs_from_all_shards, output_shard_axes, infeed_queue, device_assignment, name)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0minfeed_queue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfeed_queue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       \u001b[0mdevice_assignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_assignment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m   \u001b[0;31m# There must be at least one shard since num_shards > 0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tpu/tpu.py\u001b[0m in \u001b[0;36msplit_compile_and_replicate\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    990\u001b[0m       \u001b[0mvscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_custom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcomputation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m       \u001b[0mvscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_use_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_use_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-15bcbb644138>\u001b[0m in \u001b[0;36mgo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DCGAN_Generator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBuildGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDIR\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'DCGAN_Generator.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-15bcbb644138>\u001b[0m in \u001b[0;36mBuildGenerator\u001b[0;34m(summary, resnet, bn_momentum, bn_epsilon, name, plot)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 425\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    893\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             self.bias = self.add_weight(shape=(self.units,),\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    244\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                             constraint=constraint)\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight_regularizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m   def _variable_v2_call(cls,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m                         shape=None):\n\u001b[1;32m    196\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2501\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2502\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2503\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2504\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2505\u001b[0m     return variables.RefVariable(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1404\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m   def _init_from_args(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1558\u001b[0m               \u001b[0;34m\"construct, such as a loop or conditional. When creating a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m               \u001b[0;34m\"variable inside a loop or conditional, use a lambda as the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1560\u001b[0;31m               \"initializer.\" % name)\n\u001b[0m\u001b[1;32m   1561\u001b[0m         \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Initializer for variable dense_2/kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpl_EVu5nPyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSsRKOEjnYLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFGht3MCj45p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdHQT9xIjPLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  from keras import backend as K\n",
        "  from keras.engine import *\n",
        "  from keras.legacy import interfaces\n",
        "  from keras import activations\n",
        "  from keras import initializers\n",
        "  from keras import regularizers\n",
        "  from keras import constraints\n",
        "  from keras.utils.generic_utils import func_dump\n",
        "  from keras.utils.generic_utils import func_load\n",
        "  from keras.utils.generic_utils import deserialize_keras_object\n",
        "  from keras.utils.generic_utils import has_arg\n",
        "  from keras.utils import conv_utils\n",
        "  from keras.legacy import interfaces\n",
        "  from keras.layers import Dense, Conv1D, Conv2D, Conv3D, Conv2DTranspose, Embedding\n",
        "  import tensorflow as tf\n",
        "            \n",
        "  from keras.layers import Input, Dense, Conv2D, Add, Dot, Conv2DTranspose, Activation, Reshape,BatchNormalization,UpSampling2D,AveragePooling2D, GlobalAveragePooling2D, LeakyReLU, Reshape, Flatten\n",
        "  from keras.models import Model, Sequential\n",
        "  import keras.backend as K\n",
        "  from keras.utils import plot_model\n",
        "  from keras.layers.pooling import _GlobalPooling2D\n",
        "\n",
        "     \n",
        "  import numpy as np\n",
        "  import matplotlib.pyplot as plt\n",
        "  from time import time\n",
        "\n",
        "  from keras.models import Model, Sequential\n",
        "  from keras.optimizers import Adam\n",
        "  import keras.backend as K\n",
        "  from keras.utils.generic_utils import Progbar\n",
        "\n",
        "\n",
        "  import sys\n",
        "  import os\n",
        "  import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5dUDTWjiCd8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "30be8c2d-1b7a-471c-b2db-4e6809cb5794"
      },
      "source": [
        "def go():\n",
        "    class DenseSN(Dense):\n",
        "      def build(self, input_shape):\n",
        "          assert len(input_shape) >= 2\n",
        "          input_dim = input_shape[-1]\n",
        "          self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
        "                                        initializer=self.kernel_initializer,\n",
        "                                        name='kernel',\n",
        "                                        regularizer=self.kernel_regularizer,\n",
        "                                        constraint=self.kernel_constraint)\n",
        "          if self.use_bias:\n",
        "              self.bias = self.add_weight(shape=(self.units,),\n",
        "                                          initializer=self.bias_initializer,\n",
        "                                          name='bias',\n",
        "                                          regularizer=self.bias_regularizer,\n",
        "                                          constraint=self.bias_constraint)\n",
        "          else:\n",
        "              self.bias = None\n",
        "          self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                                  initializer=initializers.RandomNormal(0, 1),\n",
        "                                  name='sn',\n",
        "                                  trainable=False)\n",
        "          self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
        "          self.built = True\n",
        "          \n",
        "      def call(self, inputs, training=None):\n",
        "          def _l2normalize(v, eps=1e-12):\n",
        "              return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "          def power_iteration(W, u):\n",
        "              _u = u\n",
        "              _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "              _u = _l2normalize(K.dot(_v, W))\n",
        "              return _u, _v\n",
        "          W_shape = self.kernel.shape.as_list()\n",
        "          #Flatten the Tensor\n",
        "          W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "          _u, _v = power_iteration(W_reshaped, self.u)\n",
        "          #Calculate Sigma\n",
        "          sigma=K.dot(_v, W_reshaped)\n",
        "          sigma=K.dot(sigma, K.transpose(_u))\n",
        "          #normalize it\n",
        "          W_bar = W_reshaped / sigma\n",
        "          #reshape weight tensor\n",
        "          if training in {0, False}:\n",
        "              W_bar = K.reshape(W_bar, W_shape)\n",
        "          else:\n",
        "              with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                  W_bar = K.reshape(W_bar, W_shape)  \n",
        "          output = K.dot(inputs, W_bar)\n",
        "          if self.use_bias:\n",
        "              output = K.bias_add(output, self.bias, data_format='channels_last')\n",
        "          if self.activation is not None:\n",
        "              output = self.activation(output)\n",
        "          return output \n",
        "          \n",
        "    class _ConvSN(Layer):\n",
        "\n",
        "      def __init__(self, rank,\n",
        "                  filters,\n",
        "                  kernel_size,\n",
        "                  strides=1,\n",
        "                  padding='valid',\n",
        "                  data_format=None,\n",
        "                  dilation_rate=1,\n",
        "                  activation=None,\n",
        "                  use_bias=True,\n",
        "                  kernel_initializer='glorot_uniform',\n",
        "                  bias_initializer='zeros',\n",
        "                  kernel_regularizer=None,\n",
        "                  bias_regularizer=None,\n",
        "                  activity_regularizer=None,\n",
        "                  kernel_constraint=None,\n",
        "                  bias_constraint=None,\n",
        "                  spectral_normalization=True,\n",
        "                  **kwargs):\n",
        "          super(_ConvSN, self).__init__(**kwargs)\n",
        "          self.rank = rank\n",
        "          self.filters = filters\n",
        "          self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n",
        "          self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n",
        "          self.padding = conv_utils.normalize_padding(padding)\n",
        "          self.data_format = conv_utils.normalize_data_format(data_format)\n",
        "          self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, 'dilation_rate')\n",
        "          self.activation = activations.get(activation)\n",
        "          self.use_bias = use_bias\n",
        "          self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "          self.bias_initializer = initializers.get(bias_initializer)\n",
        "          self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "          self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "          self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "          self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "          self.bias_constraint = constraints.get(bias_constraint)\n",
        "          self.input_spec = InputSpec(ndim=self.rank + 2)\n",
        "          self.spectral_normalization = spectral_normalization\n",
        "          self.u = None\n",
        "          \n",
        "      def _l2normalize(self, v, eps=1e-12):\n",
        "          return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "      \n",
        "      def power_iteration(self, u, W):\n",
        "          '''\n",
        "          Accroding the paper, we only need to do power iteration one time.\n",
        "          '''\n",
        "          v = self._l2normalize(K.dot(u, K.transpose(W)))\n",
        "          u = self._l2normalize(K.dot(v, W))\n",
        "          return u, v\n",
        "      def build(self, input_shape):\n",
        "          if self.data_format == 'channels_first':\n",
        "              channel_axis = 1\n",
        "          else:\n",
        "              channel_axis = -1\n",
        "          if input_shape[channel_axis] is None:\n",
        "              raise ValueError('The channel dimension of the inputs '\n",
        "                              'should be defined. Found `None`.')\n",
        "          input_dim = input_shape[channel_axis]\n",
        "          kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "\n",
        "          self.kernel = self.add_weight(shape=kernel_shape,\n",
        "                                        initializer=self.kernel_initializer,\n",
        "                                        name='kernel',\n",
        "                                        regularizer=self.kernel_regularizer,\n",
        "                                        constraint=self.kernel_constraint)\n",
        "\n",
        "          #Spectral Normalization\n",
        "          if self.spectral_normalization:\n",
        "              self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                                      initializer=initializers.RandomNormal(0, 1),\n",
        "                                      name='sn',\n",
        "                                      trainable=False)\n",
        "          \n",
        "          if self.use_bias:\n",
        "              self.bias = self.add_weight(shape=(self.filters,),\n",
        "                                          initializer=self.bias_initializer,\n",
        "                                          name='bias',\n",
        "                                          regularizer=self.bias_regularizer,\n",
        "                                          constraint=self.bias_constraint)\n",
        "          else:\n",
        "              self.bias = None\n",
        "          # Set input spec.\n",
        "          self.input_spec = InputSpec(ndim=self.rank + 2,\n",
        "                                      axes={channel_axis: input_dim})\n",
        "          self.built = True\n",
        "\n",
        "      def call(self, inputs):\n",
        "          def _l2normalize(v, eps=1e-12):\n",
        "              return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "          def power_iteration(W, u):\n",
        "              _u = u\n",
        "              _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "              _u = _l2normalize(K.dot(_v, W))\n",
        "              return _u, _v\n",
        "          \n",
        "          if self.spectral_normalization:\n",
        "              W_shape = self.kernel.shape.as_list()\n",
        "              #Flatten the Tensor\n",
        "              W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "              _u, _v = power_iteration(W_reshaped, self.u)\n",
        "              #Calculate Sigma\n",
        "              sigma=K.dot(_v, W_reshaped)\n",
        "              sigma=K.dot(sigma, K.transpose(_u))\n",
        "              #normalize it\n",
        "              W_bar = W_reshaped / sigma\n",
        "              #reshape weight tensor\n",
        "              if training in {0, False}:\n",
        "                  W_bar = K.reshape(W_bar, W_shape)\n",
        "              else:\n",
        "                  with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                      W_bar = K.reshape(W_bar, W_shape)\n",
        "\n",
        "              #update weitht\n",
        "              self.kernel = W_bar\n",
        "          \n",
        "          if self.rank == 1:\n",
        "              outputs = K.conv1d(\n",
        "                  inputs,\n",
        "                  self.kernel,\n",
        "                  strides=self.strides[0],\n",
        "                  padding=self.padding,\n",
        "                  data_format=self.data_format,\n",
        "                  dilation_rate=self.dilation_rate[0])\n",
        "          if self.rank == 2:\n",
        "              outputs = K.conv2d(\n",
        "                  inputs,\n",
        "                  self.kernel,\n",
        "                  strides=self.strides,\n",
        "                  padding=self.padding,\n",
        "                  data_format=self.data_format,\n",
        "                  dilation_rate=self.dilation_rate)\n",
        "          if self.rank == 3:\n",
        "              outputs = K.conv3d(\n",
        "                  inputs,\n",
        "                  self.kernel,\n",
        "                  strides=self.strides,\n",
        "                  padding=self.padding,\n",
        "                  data_format=self.data_format,\n",
        "                  dilation_rate=self.dilation_rate)\n",
        "\n",
        "          if self.use_bias:\n",
        "              outputs = K.bias_add(\n",
        "                  outputs,\n",
        "                  self.bias,\n",
        "                  data_format=self.data_format)\n",
        "\n",
        "          if self.activation is not None:\n",
        "              return self.activation(outputs)\n",
        "          return outputs\n",
        "\n",
        "      def compute_output_shape(self, input_shape):\n",
        "          if self.data_format == 'channels_last':\n",
        "              space = input_shape[1:-1]\n",
        "              new_space = []\n",
        "              for i in range(len(space)):\n",
        "                  new_dim = conv_utils.conv_output_length(\n",
        "                      space[i],\n",
        "                      self.kernel_size[i],\n",
        "                      padding=self.padding,\n",
        "                      stride=self.strides[i],\n",
        "                      dilation=self.dilation_rate[i])\n",
        "                  new_space.append(new_dim)\n",
        "              return (input_shape[0],) + tuple(new_space) + (self.filters,)\n",
        "          if self.data_format == 'channels_first':\n",
        "              space = input_shape[2:]\n",
        "              new_space = []\n",
        "              for i in range(len(space)):\n",
        "                  new_dim = conv_utils.conv_output_length(\n",
        "                      space[i],\n",
        "                      self.kernel_size[i],\n",
        "                      padding=self.padding,\n",
        "                      stride=self.strides[i],\n",
        "                      dilation=self.dilation_rate[i])\n",
        "                  new_space.append(new_dim)\n",
        "              return (input_shape[0], self.filters) + tuple(new_space)\n",
        "\n",
        "      def get_config(self):\n",
        "          config = {\n",
        "              'rank': self.rank,\n",
        "              'filters': self.filters,\n",
        "              'kernel_size': self.kernel_size,\n",
        "              'strides': self.strides,\n",
        "              'padding': self.padding,\n",
        "              'data_format': self.data_format,\n",
        "              'dilation_rate': self.dilation_rate,\n",
        "              'activation': activations.serialize(self.activation),\n",
        "              'use_bias': self.use_bias,\n",
        "              'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
        "              'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "              'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
        "              'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "              'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
        "              'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "              'bias_constraint': constraints.serialize(self.bias_constraint)\n",
        "          }\n",
        "          base_config = super(_Conv, self).get_config()\n",
        "          return dict(list(base_config.items()) + list(config.items()))\n",
        "      \n",
        "    class ConvSN2D(Conv2D):\n",
        "\n",
        "      def build(self, input_shape):\n",
        "          if self.data_format == 'channels_first':\n",
        "              channel_axis = 1\n",
        "          else:\n",
        "              channel_axis = -1\n",
        "          if input_shape[channel_axis] is None:\n",
        "              raise ValueError('The channel dimension of the inputs '\n",
        "                              'should be defined. Found `None`.')\n",
        "          input_dim = input_shape[channel_axis]\n",
        "          kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "\n",
        "          self.kernel = self.add_weight(shape=kernel_shape,\n",
        "                                        initializer=self.kernel_initializer,\n",
        "                                        name='kernel',\n",
        "                                        regularizer=self.kernel_regularizer,\n",
        "                                        constraint=self.kernel_constraint)\n",
        "\n",
        "          if self.use_bias:\n",
        "              self.bias = self.add_weight(shape=(self.filters,),\n",
        "                                          initializer=self.bias_initializer,\n",
        "                                          name='bias',\n",
        "                                          regularizer=self.bias_regularizer,\n",
        "                                          constraint=self.bias_constraint)\n",
        "          else:\n",
        "              self.bias = None\n",
        "              \n",
        "          self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                          initializer=initializers.RandomNormal(0, 1),\n",
        "                          name='sn',\n",
        "                          trainable=False)\n",
        "          \n",
        "          # Set input spec.\n",
        "          self.input_spec = InputSpec(ndim=self.rank + 2,\n",
        "                                      axes={channel_axis: input_dim})\n",
        "          self.built = True\n",
        "      def call(self, inputs, training=None):\n",
        "          def _l2normalize(v, eps=1e-12):\n",
        "              return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "          def power_iteration(W, u):\n",
        "              #Accroding the paper, we only need to do power iteration one time.\n",
        "              _u = u\n",
        "              _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "              _u = _l2normalize(K.dot(_v, W))\n",
        "              return _u, _v\n",
        "          #Spectral Normalization\n",
        "          W_shape = self.kernel.shape.as_list()\n",
        "          #Flatten the Tensor\n",
        "          W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "          _u, _v = power_iteration(W_reshaped, self.u)\n",
        "          #Calculate Sigma\n",
        "          sigma=K.dot(_v, W_reshaped)\n",
        "          sigma=K.dot(sigma, K.transpose(_u))\n",
        "          #normalize it\n",
        "          W_bar = W_reshaped / sigma\n",
        "          #reshape weight tensor\n",
        "          if training in {0, False}:\n",
        "              W_bar = K.reshape(W_bar, W_shape)\n",
        "          else:\n",
        "              with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                  W_bar = K.reshape(W_bar, W_shape)\n",
        "                  \n",
        "          outputs = K.conv2d(\n",
        "                  inputs,\n",
        "                  W_bar,\n",
        "                  strides=self.strides,\n",
        "                  padding=self.padding,\n",
        "                  data_format=self.data_format,\n",
        "                  dilation_rate=self.dilation_rate)\n",
        "          if self.use_bias:\n",
        "              outputs = K.bias_add(\n",
        "                  outputs,\n",
        "                  self.bias,\n",
        "                  data_format=self.data_format)\n",
        "          if self.activation is not None:\n",
        "              return self.activation(outputs)\n",
        "          return outputs\n",
        "      \n",
        "    class ConvSN1D(Conv1D):\n",
        "      \n",
        "      def build(self, input_shape):\n",
        "          if self.data_format == 'channels_first':\n",
        "              channel_axis = 1\n",
        "          else:\n",
        "              channel_axis = -1\n",
        "          if input_shape[channel_axis] is None:\n",
        "              raise ValueError('The channel dimension of the inputs '\n",
        "                              'should be defined. Found `None`.')\n",
        "          input_dim = input_shape[channel_axis]\n",
        "          kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "\n",
        "          self.kernel = self.add_weight(shape=kernel_shape,\n",
        "                                        initializer=self.kernel_initializer,\n",
        "                                        name='kernel',\n",
        "                                        regularizer=self.kernel_regularizer,\n",
        "                                        constraint=self.kernel_constraint)\n",
        "\n",
        "          if self.use_bias:\n",
        "              self.bias = self.add_weight(shape=(self.filters,),\n",
        "                                          initializer=self.bias_initializer,\n",
        "                                          name='bias',\n",
        "                                          regularizer=self.bias_regularizer,\n",
        "                                          constraint=self.bias_constraint)\n",
        "          else:\n",
        "              self.bias = None\n",
        "              \n",
        "          self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                  initializer=initializers.RandomNormal(0, 1),\n",
        "                  name='sn',\n",
        "                  trainable=False)\n",
        "          # Set input spec.\n",
        "          self.input_spec = InputSpec(ndim=self.rank + 2,\n",
        "                                      axes={channel_axis: input_dim})\n",
        "          self.built = True\n",
        "          \n",
        "      def call(self, inputs, training=None):\n",
        "          def _l2normalize(v, eps=1e-12):\n",
        "              return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "          def power_iteration(W, u):\n",
        "              #Accroding the paper, we only need to do power iteration one time.\n",
        "              _u = u\n",
        "              _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "              _u = _l2normalize(K.dot(_v, W))\n",
        "              return _u, _v\n",
        "          #Spectral Normalization\n",
        "          W_shape = self.kernel.shape.as_list()\n",
        "          #Flatten the Tensor\n",
        "          W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "          _u, _v = power_iteration(W_reshaped, self.u)\n",
        "          #Calculate Sigma\n",
        "          sigma=K.dot(_v, W_reshaped)\n",
        "          sigma=K.dot(sigma, K.transpose(_u))\n",
        "          #normalize it\n",
        "          W_bar = W_reshaped / sigma\n",
        "          #reshape weight tensor\n",
        "          if training in {0, False}:\n",
        "              W_bar = K.reshape(W_bar, W_shape)\n",
        "          else:\n",
        "              with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                  W_bar = K.reshape(W_bar, W_shape)\n",
        "                  \n",
        "          outputs = K.conv1d(\n",
        "                  inputs,\n",
        "                  W_bar,\n",
        "                  strides=self.strides,\n",
        "                  padding=self.padding,\n",
        "                  data_format=self.data_format,\n",
        "                  dilation_rate=self.dilation_rate)\n",
        "          if self.use_bias:\n",
        "              outputs = K.bias_add(\n",
        "                  outputs,\n",
        "                  self.bias,\n",
        "                  data_format=self.data_format)\n",
        "          if self.activation is not None:\n",
        "              return self.activation(outputs)\n",
        "          return outputs\n",
        "\n",
        "    class ConvSN3D(Conv3D):    \n",
        "      def build(self, input_shape):\n",
        "          if self.data_format == 'channels_first':\n",
        "              channel_axis = 1\n",
        "          else:\n",
        "              channel_axis = -1\n",
        "          if input_shape[channel_axis] is None:\n",
        "              raise ValueError('The channel dimension of the inputs '\n",
        "                              'should be defined. Found `None`.')\n",
        "          input_dim = input_shape[channel_axis]\n",
        "          kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "\n",
        "          self.kernel = self.add_weight(shape=kernel_shape,\n",
        "                                        initializer=self.kernel_initializer,\n",
        "                                        name='kernel',\n",
        "                                        regularizer=self.kernel_regularizer,\n",
        "                                        constraint=self.kernel_constraint)\n",
        "          \n",
        "          self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                          initializer=initializers.RandomNormal(0, 1),\n",
        "                          name='sn',\n",
        "                          trainable=False)\n",
        "          \n",
        "          if self.use_bias:\n",
        "              self.bias = self.add_weight(shape=(self.filters,),\n",
        "                                          initializer=self.bias_initializer,\n",
        "                                          name='bias',\n",
        "                                          regularizer=self.bias_regularizer,\n",
        "                                          constraint=self.bias_constraint)\n",
        "          else:\n",
        "              self.bias = None\n",
        "          # Set input spec.\n",
        "          self.input_spec = InputSpec(ndim=self.rank + 2,\n",
        "                                      axes={channel_axis: input_dim})\n",
        "          self.built = True\n",
        "\n",
        "      def call(self, inputs, training=None):\n",
        "          def _l2normalize(v, eps=1e-12):\n",
        "              return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "          def power_iteration(W, u):\n",
        "              #Accroding the paper, we only need to do power iteration one time.\n",
        "              _u = u\n",
        "              _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "              _u = _l2normalize(K.dot(_v, W))\n",
        "              return _u, _v\n",
        "          #Spectral Normalization\n",
        "          W_shape = self.kernel.shape.as_list()\n",
        "          #Flatten the Tensor\n",
        "          W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "          _u, _v = power_iteration(W_reshaped, self.u)\n",
        "          #Calculate Sigma\n",
        "          sigma=K.dot(_v, W_reshaped)\n",
        "          sigma=K.dot(sigma, K.transpose(_u))\n",
        "          #normalize it\n",
        "          W_bar = W_reshaped / sigma\n",
        "          #reshape weight tensor\n",
        "          if training in {0, False}:\n",
        "              W_bar = K.reshape(W_bar, W_shape)\n",
        "          else:\n",
        "              with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                  W_bar = K.reshape(W_bar, W_shape)\n",
        "                  \n",
        "          outputs = K.conv3d(\n",
        "                  inputs,\n",
        "                  W_bar,\n",
        "                  strides=self.strides,\n",
        "                  padding=self.padding,\n",
        "                  data_format=self.data_format,\n",
        "                  dilation_rate=self.dilation_rate)\n",
        "          if self.use_bias:\n",
        "              outputs = K.bias_add(\n",
        "                  outputs,\n",
        "                  self.bias,\n",
        "                  data_format=self.data_format)\n",
        "          if self.activation is not None:\n",
        "              return self.activation(outputs)\n",
        "          return outputs\n",
        "\n",
        "          \n",
        "    class EmbeddingSN(Embedding):\n",
        "      \n",
        "      def build(self, input_shape):\n",
        "          self.embeddings = self.add_weight(\n",
        "              shape=(self.input_dim, self.output_dim),\n",
        "              initializer=self.embeddings_initializer,\n",
        "              name='embeddings',\n",
        "              regularizer=self.embeddings_regularizer,\n",
        "              constraint=self.embeddings_constraint,\n",
        "              dtype=self.dtype)\n",
        "          \n",
        "          self.u = self.add_weight(shape=tuple([1, self.embeddings.shape.as_list()[-1]]),\n",
        "                          initializer=initializers.RandomNormal(0, 1),\n",
        "                          name='sn',\n",
        "                          trainable=False)\n",
        "          \n",
        "          self.built = True\n",
        "          \n",
        "      def call(self, inputs):\n",
        "          if K.dtype(inputs) != 'int32':\n",
        "              inputs = K.cast(inputs, 'int32')\n",
        "              \n",
        "          def _l2normalize(v, eps=1e-12):\n",
        "              return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "          def power_iteration(W, u):\n",
        "              #Accroding the paper, we only need to do power iteration one time.\n",
        "              _u = u\n",
        "              _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "              _u = _l2normalize(K.dot(_v, W))\n",
        "              return _u, _v\n",
        "          W_shape = self.embeddings.shape.as_list()\n",
        "          #Flatten the Tensor\n",
        "          W_reshaped = K.reshape(self.embeddings, [-1, W_shape[-1]])\n",
        "          _u, _v = power_iteration(W_reshaped, self.u)\n",
        "          #Calculate Sigma\n",
        "          sigma=K.dot(_v, W_reshaped)\n",
        "          sigma=K.dot(sigma, K.transpose(_u))\n",
        "          #normalize it\n",
        "          W_bar = W_reshaped / sigma\n",
        "          #reshape weight tensor\n",
        "          if training in {0, False}:\n",
        "              W_bar = K.reshape(W_bar, W_shape)\n",
        "          else:\n",
        "              with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                  W_bar = K.reshape(W_bar, W_shape)\n",
        "          self.embeddings = W_bar\n",
        "              \n",
        "          out = K.gather(self.embeddings, inputs)\n",
        "          return out \n",
        "\n",
        "    class ConvSN2DTranspose(Conv2DTranspose):\n",
        "\n",
        "      def build(self, input_shape):\n",
        "          if len(input_shape) != 4:\n",
        "              raise ValueError('Inputs should have rank ' +\n",
        "                              str(4) +\n",
        "                              '; Received input shape:', str(input_shape))\n",
        "          if self.data_format == 'channels_first':\n",
        "              channel_axis = 1\n",
        "          else:\n",
        "              channel_axis = -1\n",
        "          if input_shape[channel_axis] is None:\n",
        "              raise ValueError('The channel dimension of the inputs '\n",
        "                              'should be defined. Found `None`.')\n",
        "          input_dim = input_shape[channel_axis]\n",
        "          kernel_shape = self.kernel_size + (self.filters, input_dim)\n",
        "\n",
        "          self.kernel = self.add_weight(shape=kernel_shape,\n",
        "                                        initializer=self.kernel_initializer,\n",
        "                                        name='kernel',\n",
        "                                        regularizer=self.kernel_regularizer,\n",
        "                                        constraint=self.kernel_constraint)\n",
        "          if self.use_bias:\n",
        "              self.bias = self.add_weight(shape=(self.filters,),\n",
        "                                          initializer=self.bias_initializer,\n",
        "                                          name='bias',\n",
        "                                          regularizer=self.bias_regularizer,\n",
        "                                          constraint=self.bias_constraint)\n",
        "          else:\n",
        "              self.bias = None\n",
        "              \n",
        "          self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n",
        "                          initializer=initializers.RandomNormal(0, 1),\n",
        "                          name='sn',\n",
        "                          trainable=False)\n",
        "          \n",
        "          # Set input spec.\n",
        "          self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n",
        "          self.built = True  \n",
        "      \n",
        "      def call(self, inputs):\n",
        "          input_shape = K.shape(inputs)\n",
        "          batch_size = input_shape[0]\n",
        "          if self.data_format == 'channels_first':\n",
        "              h_axis, w_axis = 2, 3\n",
        "          else:\n",
        "              h_axis, w_axis = 1, 2\n",
        "\n",
        "          height, width = input_shape[h_axis], input_shape[w_axis]\n",
        "          kernel_h, kernel_w = self.kernel_size\n",
        "          stride_h, stride_w = self.strides\n",
        "          if self.output_padding is None:\n",
        "              out_pad_h = out_pad_w = None\n",
        "          else:\n",
        "              out_pad_h, out_pad_w = self.output_padding\n",
        "\n",
        "          # Infer the dynamic output shape:\n",
        "          out_height = conv_utils.deconv_length(height,\n",
        "                                                stride_h, kernel_h,\n",
        "                                                self.padding,\n",
        "                                                out_pad_h)\n",
        "          out_width = conv_utils.deconv_length(width,\n",
        "                                              stride_w, kernel_w,\n",
        "                                              self.padding,\n",
        "                                              out_pad_w)\n",
        "          if self.data_format == 'channels_first':\n",
        "              output_shape = (batch_size, self.filters, out_height, out_width)\n",
        "          else:\n",
        "              output_shape = (batch_size, out_height, out_width, self.filters)\n",
        "              \n",
        "          #Spectral Normalization    \n",
        "          def _l2normalize(v, eps=1e-12):\n",
        "              return v / (K.sum(v ** 2) ** 0.5 + eps)\n",
        "          def power_iteration(W, u):\n",
        "              #Accroding the paper, we only need to do power iteration one time.\n",
        "              _u = u\n",
        "              _v = _l2normalize(K.dot(_u, K.transpose(W)))\n",
        "              _u = _l2normalize(K.dot(_v, W))\n",
        "              return _u, _v\n",
        "          W_shape = self.kernel.shape.as_list()\n",
        "          #Flatten the Tensor\n",
        "          W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n",
        "          _u, _v = power_iteration(W_reshaped, self.u)\n",
        "          #Calculate Sigma\n",
        "          sigma=K.dot(_v, W_reshaped)\n",
        "          sigma=K.dot(sigma, K.transpose(_u))\n",
        "          #normalize it\n",
        "          W_bar = W_reshaped / sigma\n",
        "          #reshape weight tensor\n",
        "          if training in {0, False}:\n",
        "              W_bar = K.reshape(W_bar, W_shape)\n",
        "          else:\n",
        "              with tf.control_dependencies([self.u.assign(_u)]):\n",
        "                  W_bar = K.reshape(W_bar, W_shape)\n",
        "          self.kernel = W_bar\n",
        "          \n",
        "          outputs = K.conv2d_transpose(\n",
        "              inputs,\n",
        "              self.kernel,\n",
        "              output_shape,\n",
        "              self.strides,\n",
        "              padding=self.padding,\n",
        "              data_format=self.data_format)\n",
        "\n",
        "          if self.use_bias:\n",
        "              outputs = K.bias_add(\n",
        "                  outputs,\n",
        "                  self.bias,\n",
        "                  data_format=self.data_format)\n",
        "\n",
        "          if self.activation is not None:\n",
        "              return self.activation(outputs)\n",
        "          return outputs\n",
        "def model():\n",
        "  class GlobalSumPooling2D(_GlobalPooling2D):\n",
        "        \"\"\"Global sum pooling operation for spatial data.\n",
        "        # Arguments\n",
        "            data_format: A string,\n",
        "                one of `channels_last` (default) or `channels_first`.\n",
        "                The ordering of the dimensions in the inputs.\n",
        "                `channels_last` corresponds to inputs with shape\n",
        "                `(batch, height, width, channels)` while `channels_first`\n",
        "                corresponds to inputs with shape\n",
        "                `(batch, channels, height, width)`.\n",
        "                It defaults to the `image_data_format` value found in your\n",
        "                Keras config file at `~/.keras/keras.json`.\n",
        "                If you never set it, then it will be \"channels_last\".\n",
        "        # Input shape\n",
        "            - If `data_format='channels_last'`:\n",
        "                4D tensor with shape:\n",
        "                `(batch_size, rows, cols, channels)`\n",
        "            - If `data_format='channels_first'`:\n",
        "                4D tensor with shape:\n",
        "                `(batch_size, channels, rows, cols)`\n",
        "        # Output shape\n",
        "            2D tensor with shape:\n",
        "            `(batch_size, channels)`\n",
        "        \"\"\"\n",
        "\n",
        "        def call(self, inputs):\n",
        "            if self.data_format == 'channels_last':\n",
        "                return K.sum(inputs, axis=[1, 2])\n",
        "            else:\n",
        "                return K.sum(inputs, axis=[2, 3])\n",
        "\n",
        "\n",
        "    def ResBlock(input_shape, sampling=None, trainable_sortcut=True, \n",
        "                spectral_normalization=False, batch_normalization=True,\n",
        "                bn_momentum=0.9, bn_epsilon=0.00002,\n",
        "                channels=256, k_size=3, summary=False,\n",
        "                plot=False, name=None):\n",
        "        '''\n",
        "        ResBlock(input_shape, sampling=None, trainable_sortcut=True, \n",
        "                spectral_normalization=False, batch_normalization=True,\n",
        "                bn_momentum=0.9, bn_epsilon=0.00002,\n",
        "                channels=256, k_size=3, summary=False,\n",
        "                plot=False, plot_name='res_block.png')\"\"\n",
        "                \n",
        "        Build ResBlock as keras Model\n",
        "        sampleing = 'up' for upsampling\n",
        "                    'down' for downsampling(AveragePooling)\n",
        "                    None for none\n",
        "        \n",
        "        '''\n",
        "        #input_shape = input_layer.sahpe.as_list()\n",
        "        \n",
        "        res_block_input = Input(shape=input_shape)\n",
        "        \n",
        "        if batch_normalization:\n",
        "            res_block_1 = BatchNormalization(momentum=bn_momentum, epsilon=bn_epsilon)(res_block_input)\n",
        "        else:\n",
        "            res_block_1 = res_block_input\n",
        "            \n",
        "        res_block_1     = Activation('relu')(res_block_1)\n",
        "        \n",
        "        if spectral_normalization:\n",
        "            res_block_1     = ConvSN2D(channels, k_size , strides=1, padding='same',kernel_initializer='glorot_uniform')(res_block_1)\n",
        "        else:\n",
        "            res_block_1     = Conv2D(channels, k_size , strides=1, padding='same',kernel_initializer='glorot_uniform')(res_block_1)\n",
        "        \n",
        "        if sampling=='up':\n",
        "            res_block_1     = UpSampling2D()(res_block_1)\n",
        "        else:\n",
        "            pass\n",
        "        \n",
        "        if batch_normalization:\n",
        "            res_block_2     = BatchNormalization(momentum=bn_momentum, epsilon=bn_epsilon)(res_block_1)\n",
        "        else:\n",
        "            res_block_2     = res_block_1\n",
        "        res_block_2     = Activation('relu')(res_block_2)\n",
        "        \n",
        "        if spectral_normalization:\n",
        "            res_block_2     = ConvSN2D(channels, k_size , strides=1, padding='same',kernel_initializer='glorot_uniform')(res_block_2)\n",
        "        else:\n",
        "            res_block_2     = Conv2D(channels, k_size , strides=1, padding='same',kernel_initializer='glorot_uniform')(res_block_2)\n",
        "        \n",
        "        if sampling=='down':\n",
        "            res_block_2 = AveragePooling2D()(res_block_2)\n",
        "        else:\n",
        "            pass\n",
        "        \n",
        "        if trainable_sortcut:\n",
        "            if spectral_normalization:\n",
        "                short_cut = ConvSN2D(channels, 1 , strides=1, padding='same',kernel_initializer='glorot_uniform')(res_block_input)\n",
        "            else:\n",
        "                short_cut = Conv2D(channels, 1 , strides=1, padding='same',kernel_initializer='glorot_uniform')(res_block_input)\n",
        "        else:\n",
        "            short_cut = res_block_input\n",
        "            \n",
        "        if sampling=='up':\n",
        "            short_cut       = UpSampling2D()(short_cut)\n",
        "        elif sampling=='down':\n",
        "            short_cut       = AveragePooling2D()(short_cut)\n",
        "        elif sampling=='None':\n",
        "            pass\n",
        "\n",
        "        res_block_add   = Add()([short_cut, res_block_2])\n",
        "        \n",
        "        res_block = Model(res_block_input, res_block_add, name=name)\n",
        "        \n",
        "        if plot:\n",
        "            plot_model(res_block, name+'.png', show_layer_names=False)\n",
        "        if summary:\n",
        "            print(name)\n",
        "            res_block.summary()\n",
        "        \n",
        "        return res_block\n",
        "        \n",
        "    def BuildGenerator(summary=True, resnet=True, bn_momentum=0.9, bn_epsilon=0.00002, name='Generator', plot=False):\n",
        "        if resnet:\n",
        "            model_input = Input(shape=(128,))\n",
        "            h           = Dense(4*4*256, kernel_initializer='glorot_uniform')(model_input)\n",
        "            h           = Reshape((4,4,256))(h)\n",
        "            resblock_1  = ResBlock(input_shape=(4,4,256), sampling='up', bn_epsilon=bn_epsilon, bn_momentum=bn_momentum, name='Generator_resblock_1')\n",
        "            h           = resblock_1(h)\n",
        "            resblock_2  = ResBlock(input_shape=(8,8,256), sampling='up', bn_epsilon=bn_epsilon, bn_momentum=bn_momentum, name='Generator_resblock_2')\n",
        "            h           = resblock_2(h)\n",
        "            resblock_3  = ResBlock(input_shape=(16,16,256), sampling='up', bn_epsilon=bn_epsilon, bn_momentum=bn_momentum, name='Generator_resblock_3')\n",
        "            h           = resblock_3(h)\n",
        "            h           = BatchNormalization(epsilon=bn_epsilon, momentum=bn_momentum)(h)\n",
        "            h           = Activation('relu')(h)\n",
        "            model_output= Conv2D(1,   kernel_size=3, strides=1, padding='same', activation='tanh')(h)\n",
        "            model = Model(model_input, model_output,name=name)\n",
        "            \n",
        "        else:\n",
        "            model = Sequential(name=name)\n",
        "            model.add(Dense(4*4*512, kernel_initializer='glorot_uniform' , input_dim=128))\n",
        "            model.add(Reshape((4,4,512)))\n",
        "            model.add(Conv2DTranspose(256, kernel_size=4, strides=2, padding='same', activation='relu',kernel_initializer='glorot_uniform'))\n",
        "            model.add(BatchNormalization(epsilon=bn_epsilon, momentum=bn_momentum))\n",
        "            model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu',kernel_initializer='glorot_uniform'))\n",
        "            model.add(BatchNormalization(epsilon=bn_epsilon, momentum=bn_momentum))\n",
        "            model.add(Conv2DTranspose(64,  kernel_size=4, strides=2, padding='same', activation='relu',kernel_initializer='glorot_uniform'))\n",
        "            model.add(BatchNormalization(epsilon=bn_epsilon, momentum=bn_momentum))\n",
        "            model.add(Conv2DTranspose(1,   kernel_size=3, strides=1, padding='same', activation='tanh'))\n",
        "            \n",
        "        if plot:\n",
        "            plot_model(model, name+'.png', show_layer_names=True)\n",
        "        if summary:\n",
        "            print(\"Generator\")\n",
        "            model.summary()\n",
        "        return model\n",
        "\n",
        "    def BuildDiscriminator(summary=True, spectral_normalization=True, batch_normalization=False, bn_momentum=0.9, bn_epsilon=0.00002, resnet=True, name='Discriminator', plot=False):\n",
        "        if resnet:\n",
        "            model_input = Input(shape=(32,32,1))\n",
        "            resblock_1  = ResBlock(input_shape=(32,32,1), channels=128, sampling='down', batch_normalization=True, spectral_normalization=spectral_normalization, name='Discriminator_resblock_Down_1')\n",
        "            h           = resblock_1(model_input)\n",
        "            resblock_2  = ResBlock(input_shape=(16,16,128),channels=128, sampling='down', batch_normalization=True, spectral_normalization=spectral_normalization, name='Discriminator_resblock_Down_2')\n",
        "            h           = resblock_2(h)\n",
        "            resblock_3  = ResBlock(input_shape=(8,8,128),channels=128 , sampling=None, batch_normalization=True, spectral_normalization=spectral_normalization, trainable_sortcut=False, name='Discriminator_resblock_1' )\n",
        "            h           = resblock_3(h)\n",
        "            resblock_4  = ResBlock(input_shape=(8,8,128),channels=128 , sampling=None, batch_normalization=True, spectral_normalization=spectral_normalization, trainable_sortcut=False, name='Discriminator_resblock_2' )\n",
        "            h           = resblock_4(h)\n",
        "            h           = Activation('relu')(h)\n",
        "            h           = GlobalSumPooling2D()(h)\n",
        "            model_output= DenseSN(1,kernel_initializer='glorot_uniform')(h)\n",
        "\n",
        "            model = Model(model_input, model_output, name=name)\n",
        "\n",
        "        else:\n",
        "            if spectral_normalization:\n",
        "                model = Sequential(name=name)\n",
        "                model.add(ConvSN2D(64, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same', input_shape=(32,32,1) ))\n",
        "                model.add(LeakyReLU(0.1))\n",
        "                model.add(ConvSN2D(64, kernel_size=4, strides=2,kernel_initializer='glorot_uniform', padding='same'))\n",
        "                model.add(LeakyReLU(0.1))\n",
        "                model.add(ConvSN2D(128, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same'))\n",
        "                model.add(LeakyReLU(0.1))\n",
        "                model.add(ConvSN2D(128, kernel_size=4, strides=2,kernel_initializer='glorot_uniform', padding='same'))\n",
        "                model.add(LeakyReLU(0.1))\n",
        "                model.add(ConvSN2D(256, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same'))\n",
        "                model.add(LeakyReLU(0.1))\n",
        "                model.add(ConvSN2D(256, kernel_size=4, strides=2,kernel_initializer='glorot_uniform', padding='same'))\n",
        "                model.add(LeakyReLU(0.1))\n",
        "                model.add(ConvSN2D(512, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same'))\n",
        "                model.add(LeakyReLU(0.1))\n",
        "                model.add(GlobalSumPooling2D())\n",
        "                model.add(DenseSN(1,kernel_initializer='glorot_uniform'))\n",
        "            else:\n",
        "                model = Sequential(name=name)\n",
        "                model.add(Conv2D(64, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same', input_shape=(32,32,1) ))\n",
        "                model.add(LeakyReLU(0.1))\n",
        "                model.add(Conv2D(64, kernel_size=4, strides=2,kernel_initializer='glorot_uniform', padding='same'))\n",
        "                model.add(LeakyReLU(0.1))\n",
        "                model.add(Conv2D(128, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same'))\n",
        "                model.add(LeakyReLU(0.1))\n",
        "                model.add(Conv2D(128, kernel_size=4, strides=2,kernel_initializer='glorot_uniform', padding='same'))\n",
        "                model.add(LeakyReLU(0.1))\n",
        "                model.add(Conv2D(256, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same'))\n",
        "                model.add(LeakyReLU(0.1))\n",
        "                model.add(Conv2D(256, kernel_size=4, strides=2,kernel_initializer='glorot_uniform', padding='same'))\n",
        "                model.add(LeakyReLU(0.1))\n",
        "                model.add(Conv2D(512, kernel_size=3, strides=1,kernel_initializer='glorot_uniform', padding='same'))\n",
        "                model.add(LeakyReLU(0.1))\n",
        "                model.add(GlobalSumPooling2D())\n",
        "                model.add(Dense(1,kernel_initializer='glorot_uniform'))\n",
        "        if plot:\n",
        "            plot_model(model, name+'.png', show_layer_names=True)\n",
        "            \n",
        "        if summary:\n",
        "            print('Discriminator')\n",
        "            print('Spectral Normalization: {}'.format(spectral_normalization))\n",
        "            model.summary()\n",
        "        return model\n",
        "\n",
        "    if __name__ == '__main__':\n",
        "      print('Plot the model visualization')\n",
        "      from keras.utils import plot_model\n",
        "      DIR = '/tmp/'\n",
        "      \n",
        "      print('DCGAN_Generator')\n",
        "      model = BuildGenerator(resnet=False)\n",
        "      plot_model(model, show_shapes=True, to_file=DIR+'DCGAN_Generator.png')\n",
        "      \n",
        "      print('ResNet_Generator')\n",
        "      model = BuildGenerator(resnet=True)\n",
        "      plot_model(model, show_shapes=True, to_file=DIR+'ResNet_Generator.png')\n",
        "\n",
        "      \n",
        "      print('DCGAN_Discriminator')\n",
        "      model = BuildDiscriminator(resnet=False)\n",
        "      plot_model(model, show_shapes=True, to_file=DIR+'DCGAN_Discriminator.png')\n",
        "      \n",
        "      print('ResNet_Discriminator')\n",
        "      model = BuildDiscriminator(resnet=True)\n",
        "      plot_model(model, show_shapes=True, to_file=DIR+'ResNet_Discriminator.png')\n",
        "      \n",
        "      \n",
        "      print('Generator_resblock_1')\n",
        "      model = ResBlock(input_shape=(4,4,256), sampling='up',  name='Generator_resblock_1')\n",
        "      plot_model(model, show_shapes=True, to_file=DIR+'Generator_resblock_1.png')\n",
        "\n",
        "      \n",
        "      print('Discriminator_resblock_Down_1')\n",
        "      model = ResBlock(input_shape=(32,32,1), channels=128, sampling='down', spectral_normalization=True, name='Discriminator_resblock_Down_1')\n",
        "      plot_model(model, show_shapes=True, to_file=DIR+'Discriminator_resblock_Down_1.png')\n",
        "      \n",
        "      print('Discriminator_resblock_1')\n",
        "      model = ResBlock(input_shape=(8,8,128),channels=128 , sampling=None, spectral_normalization=True, name='Discriminator_resblock_1' )\n",
        "      plot_model(model, show_shapes=True, to_file=DIR+'Discriminator_resblock_1.png')\n",
        "\n",
        "\n",
        "    \n",
        "def train():\n",
        "    arg_list = [\":)\",'dcgan',\"SN\", \"nope\", \"nah\"]\n",
        "    plt.switch_backend('agg') \n",
        "    #Hyperperemeter\n",
        "    BATCHSIZE=64\n",
        "    LEARNING_RATE = 0.0002\n",
        "    TRAINING_RATIO = 1\n",
        "    BETA_1 = 0.0\n",
        "    BETA_2 = 0.9\n",
        "    EPOCHS = 500\n",
        "    BN_MIMENTUM = 0.9\n",
        "    BN_EPSILON  = 0.00002\n",
        "    LEAK = 0.1\n",
        "    LOSS = 'hinge' #Or\n",
        "    #LOSS = 'wasserstein' #Or\n",
        "    #LOSS = 'binary_crossentropy'\n",
        "\n",
        "    if arg_list[1].lower == \"dcgan\":\n",
        "        RESNET = False #for DCGAN\n",
        "    elif arg_list[1].lower == \"resnet\":\n",
        "        RESNET = True #for DCGAN\n",
        "    else:\n",
        "        RESNET = True\n",
        "\n",
        "    if arg_list[2].lower == \"SN\":\n",
        "        SN = True \n",
        "    else:\n",
        "        SN = False\n",
        "    if arg_list[3].lower == \"GP\":\n",
        "        GP = True\n",
        "        from functools import partial\n",
        "        LAMDA = 10\n",
        "    else:\n",
        "        GP = False\n",
        "        \n",
        "    SAVE_DIR = '/tmp/{}/generated_img_doodles_{}_{}_{}/'.format(LOSS, arg_list[1], arg_list[2], arg_list[3])\n",
        "\n",
        "    if not os.path.isdir('/tmp/'+LOSS):\n",
        "        print('mkdir {}'.format('/tmp/'+LOSS))\n",
        "        os.mkdir('/tmp/'+LOSS)\n",
        "\n",
        "    if not os.path.isdir(SAVE_DIR):\n",
        "        print('mkdir {}'.format(SAVE_DIR))\n",
        "        os.mkdir(SAVE_DIR)\n",
        "\n",
        "    PLOT_MODEL = False\n",
        "    SUMMARY = True\n",
        "    RESIST_GPU_MEM = True\n",
        "    GENERATE_ROW_NUM = 8\n",
        "    GENERATE_BATCHSIZE = GENERATE_ROW_NUM*GENERATE_ROW_NUM\n",
        "\n",
        "    if RESIST_GPU_MEM:\n",
        "        # for resist GPU memory (Only in TensorFlow Backend)\n",
        "        if K.backend() == 'tensorflow':\n",
        "            import tensorflow as tf\n",
        "            config = tf.ConfigProto()\n",
        "            config.gpu_options.allow_growth=True\n",
        "            sess = tf.Session(config=config)\n",
        "            K.set_session(sess)\n",
        "\n",
        "    # wasserstein_loss\n",
        "    def wasserstein_loss(y_true, y_pred):\n",
        "        return K.mean(y_true*y_pred)\n",
        "\n",
        "    def hinge_G_loss(y_true, y_pred):\n",
        "        return -K.mean(y_pred)\n",
        "\n",
        "    def hinge_D_real_loss(y_true, y_pred):\n",
        "        return K.mean(K.relu(1-y_pred))\n",
        "\n",
        "    def hinge_D_fake_loss(y_true, y_pred):\n",
        "        return K.mean(K.relu(1+y_pred))\n",
        "\n",
        "    if LOSS == 'wasserstein':\n",
        "        G_LOSS = wasserstein_loss\n",
        "        D_real_LOSS = wasserstein_loss\n",
        "        D_fake_LOSS = wasserstein_loss\n",
        "    elif LOSS == 'binary_crossentropy':\n",
        "        G_LOSS = LOSS\n",
        "        D_real_LOSS = LOSS\n",
        "        D_fake_LOSS = LOSS\n",
        "    elif LOSS == 'hinge':\n",
        "        G_LOSS = hinge_G_loss\n",
        "        D_real_LOSS = hinge_D_real_loss\n",
        "        D_fake_LOSS = hinge_D_fake_loss\n",
        "    #Build Model\n",
        "    generator = BuildGenerator(bn_momentum=BN_MIMENTUM, bn_epsilon=BN_EPSILON, resnet=RESNET, plot=PLOT_MODEL, summary=SUMMARY)\n",
        "    discriminator = BuildDiscriminator(resnet=RESNET,spectral_normalization=SN, plot=PLOT_MODEL, summary=SUMMARY)\n",
        "\n",
        "    #Build Model for Training\n",
        "    if GP:\n",
        "        from keras.layers.merge import _Merge\n",
        "        \n",
        "        def gradient_penalty_loss(y_true, y_pred, averaged_samples, gradient_penalty_weight):\n",
        "            # first get the gradients:\n",
        "            #   assuming: - that y_pred has dimensions (batch_size, 1)\n",
        "            #             - averaged_samples has dimensions (batch_size, nbr_features)\n",
        "            # gradients afterwards has dimension (batch_size, nbr_features), basically\n",
        "            # a list of nbr_features-dimensional gradient vectors\n",
        "            gradients = K.gradients(y_pred, averaged_samples)[0]\n",
        "            # compute the euclidean norm by squaring ...\n",
        "            gradients_sqr = K.square(gradients)\n",
        "            #   ... summing over the rows ...\n",
        "            gradients_sqr_sum = K.sum(gradients_sqr,\n",
        "                                      axis=np.arange(1, len(gradients_sqr.shape)))\n",
        "            #   ... and sqrt\n",
        "            gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
        "            # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
        "            gradient_penalty = gradient_penalty_weight * K.square(1 - gradient_l2_norm)\n",
        "            # return the mean as loss over all the batch samples\n",
        "            return K.mean(gradient_penalty)\n",
        "        \n",
        "        \n",
        "        class RandomWeightedAverage(_Merge):\n",
        "            \"\"\"Takes a randomly-weighted average of two tensors. In geometric terms, this outputs a random point on the line\n",
        "            between each pair of input points.\n",
        "            Inheriting from _Merge is a little messy but it was the quickest solution I could think of.\n",
        "            Improvements appreciated.\"\"\"\n",
        "\n",
        "            def _merge_function(self, inputs):\n",
        "                weights = K.random_uniform((BATCHSIZE, 1, 1, 1))\n",
        "                return (weights * inputs[0]) + ((1 - weights) * inputs[1])\n",
        "        \n",
        "        Noise_input_for_training_generator = Input(shape=(128,))\n",
        "        Generated_image                    = generator(Noise_input_for_training_generator)\n",
        "        Discriminator_output               = discriminator(Generated_image)\n",
        "        model_for_training_generator       = Model(Noise_input_for_training_generator, Discriminator_output)\n",
        "        discriminator.trainable = False\n",
        "        if SUMMARY:\n",
        "            print(\"model_for_training_generator\")\n",
        "            model_for_training_generator.summary()\n",
        "\n",
        "        model_for_training_generator.compile(optimizer=Adam(LEARNING_RATE, beta_1=BETA_1, beta_2=BETA_2), loss=G_LOSS)\n",
        "\n",
        "        model_for_training_generator = tf.contrib.tpu.keras_to_tpu_model(\n",
        "            model_for_training_generator,\n",
        "            strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "            tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "        \n",
        "\n",
        "        Real_image                             = Input(shape=(32,32,1))\n",
        "        Noise_input_for_training_discriminator = Input(shape=(128,))\n",
        "        Fake_image                             = generator(Noise_input_for_training_discriminator)\n",
        "        Averaged_samples                       = RandomWeightedAverage()([Real_image, Fake_image])\n",
        "        Discriminator_output_for_real          = discriminator(Real_image)\n",
        "        Discriminator_output_for_fake          = discriminator(Fake_image)\n",
        "        Discriminator_output_for_averaged_samples = discriminator(Averaged_samples)\n",
        "\n",
        "        model_for_training_discriminator       = Model([Real_image,\n",
        "                                                        Noise_input_for_training_discriminator],\n",
        "                                                      [Discriminator_output_for_real,\n",
        "                                                        Discriminator_output_for_fake,\n",
        "                                                        Discriminator_output_for_averaged_samples])\n",
        "        generator.trainable = False\n",
        "        discriminator.trainable = True\n",
        "        model_for_training_discriminator.compile(optimizer=Adam(LEARNING_RATE*TRAINING_RATIO, beta_1=BETA_1, beta_2=BETA_2), loss=[D_real_LOSS, D_fake_LOSS])\n",
        "        \n",
        "        model_for_training_discriminator = tf.contrib.tpu.keras_to_tpu_model(\n",
        "            model_for_training_discriminator,\n",
        "            strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "            tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))              \n",
        "            \n",
        "        if SUMMARY:\n",
        "            print(\"model_for_training_discriminator\")\n",
        "            model_for_training_discriminator.summary()\n",
        "        partial_gp_loss = partial(gradient_penalty_loss,\n",
        "                              averaged_samples=averaged_samples,\n",
        "                              gradient_penalty_weight=LAMDA)\n",
        "        partial_gp_loss.__name__ = 'gradient_penalty'\n",
        "        \n",
        "    else:\n",
        "        Noise_input_for_training_generator = Input(shape=(128,))\n",
        "        Generated_image                    = generator(Noise_input_for_training_generator)\n",
        "        Discriminator_output               = discriminator(Generated_image)\n",
        "        model_for_training_generator       = Model(Noise_input_for_training_generator, Discriminator_output)\n",
        "        discriminator.trainable = False\n",
        "        if SUMMARY:\n",
        "            print(\"model_for_training_generator\")\n",
        "            model_for_training_generator.summary()\n",
        "\n",
        "        model_for_training_generator.compile(optimizer=Adam(LEARNING_RATE, beta_1=BETA_1, beta_2=BETA_2), loss=G_LOSS)\n",
        "\n",
        "        model_for_training_generator = tf.contrib.tpu.keras_to_tpu_model(\n",
        "            model_for_training_generator,\n",
        "            strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "            tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "        \n",
        "\n",
        "        Real_image                             = Input(shape=(32,32,1))\n",
        "        Noise_input_for_training_discriminator = Input(shape=(128,))\n",
        "        Fake_image                             = generator(Noise_input_for_training_discriminator)\n",
        "        Discriminator_output_for_real          = discriminator(Real_image)\n",
        "        Discriminator_output_for_fake          = discriminator(Fake_image)\n",
        "\n",
        "        model_for_training_discriminator       = Model([Real_image,\n",
        "                                                        Noise_input_for_training_discriminator],\n",
        "                                                      [Discriminator_output_for_real,\n",
        "                                                        Discriminator_output_for_fake])\n",
        "        generator.trainable = False\n",
        "        discriminator.trainable = True\n",
        "        model_for_training_discriminator.compile(optimizer=Adam(LEARNING_RATE*TRAINING_RATIO, beta_1=BETA_1, beta_2=BETA_2), loss=[D_real_LOSS, D_fake_LOSS])\n",
        "        \n",
        "        model_for_training_discriminator = tf.contrib.tpu.keras_to_tpu_model(\n",
        "            model_for_training_discriminator,\n",
        "            strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "            tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))     \n",
        "        \n",
        "        if SUMMARY:\n",
        "            print(\"model_for_training_discriminator\")\n",
        "            model_for_training_discriminator.summary()\n",
        "\n",
        "\n",
        "    project_id = \"vandyhacks-257821\"\n",
        "\n",
        "    import uuid\n",
        "    bucket_name = \"tboard_logs\"\n",
        "        \n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "\n",
        "    !gcloud config set project {project_id}\n",
        "\n",
        "    with open('/tmp/to_upload.txt', 'w') as f:\n",
        "      f.write('my sample file')\n",
        "\n",
        "    print('/tmp/to_upload.txt contains:')\n",
        "    !cat /tmp/to_upload.txt\n",
        "    !gsutil cp /tmp/to_upload.txt gs://{bucket_name}/\n",
        "\n",
        "    !gsutil cp gs://{bucket_name}/to_upload.txt /tmp/gsutil_download.txt\n",
        "      \n",
        "    # Print the result to make sure the transfer worked.\n",
        "    !cat /tmp/gsutil_download.txt\n",
        "\n",
        "\n",
        "    !gsutil cp -r \"gs://{bucket_name}/training2/training_2\" \"/training2/\"\n",
        "\n",
        "\n",
        "    alarm = np.load(r\"/training2/training_2/alarm clock/alarm clock113911.npy\") \n",
        "    apple= np.load(r\"/training2/training_2/apple/apple139902.npy\") \n",
        "    coffee=np.load(r\"/training2/training_2/coffee cup/coffee cup161463.npy\") \n",
        "    glasses=np.load(r\"/training2/training_2/eyeglasses/eyeglasses203817.npy\") \n",
        "    fish=np.load(r\"/training2/training_2/fish/fish126420.npy\") \n",
        "    flower=np.load(r\"/training2/training_2/flower/flower138836.npy\") \n",
        "    leaf=np.load(r\"/training2/training_2/leaf/leaf116425.npy\") \n",
        "    pig=np.load(r\"/training2/training_2/pig/pig164788.npy\") \n",
        "    face=np.load(r\"/training2/training_2/smiley face/smiley face119479.npy\") \n",
        "    mona=np.load(r\"/training2/training_2/The Mona Lisa/The Mona Lisa111580.npy\") \n",
        "    train = np.concatenate((alarm, apple, coffee, glasses, fish, flower, leaf, pig, face, mona), axis=0)\n",
        "    #Load data\n",
        "    train = train.reshape(train.shape[0], 32, 32, 1).astype('float32')\n",
        "    train_images = (train *2) - 1 # Normalize the images to [-1, 1]\n",
        "    ## Normalize it \n",
        "    X = train_images\n",
        "\n",
        "    # Make Label for traing\n",
        "    if LOSS == 'binary_crossentropy':\n",
        "        fake_y = np.zeros((BATCHSIZE, 1), dtype=np.float32)\n",
        "        real_y = np.ones((BATCHSIZE, 1), dtype=np.float32)\n",
        "    else:\n",
        "        fake_y = np.ones((BATCHSIZE, 1), dtype=np.float32)\n",
        "        real_y = -fake_y\n",
        "\n",
        "    if GP:\n",
        "        dummy_y = np.zeros((BATCHSIZE, 1), dtype=np.float32)\n",
        "                          \n",
        "    test_noise = np.random.randn(GENERATE_BATCHSIZE, 128)\n",
        "\n",
        "    discriminator_loss = []\n",
        "    generator_loss = []\n",
        "\n",
        "    if GP:\n",
        "        for epoch in range(EPOCHS):\n",
        "            np.random.shuffle(X)\n",
        "\n",
        "            print(\"epoch {} of {}\".format(epoch+1, EPOCHS))\n",
        "            num_batches = int(X.shape[0] // BATCHSIZE)\n",
        "\n",
        "            print(\"number of batches: {}\".format(int(X.shape[0] // (BATCHSIZE))))\n",
        "\n",
        "            progress_bar = Progbar(target=int(X.shape[0] // (BATCHSIZE * TRAINING_RATIO)))\n",
        "            minibatches_size = BATCHSIZE * TRAINING_RATIO\n",
        "\n",
        "            start_time = time()\n",
        "            for index in range(int(X.shape[0] // (BATCHSIZE * TRAINING_RATIO))):\n",
        "                progress_bar.update(index)\n",
        "                discriminator_minibatches = X[index * minibatches_size:(index + 1) * minibatches_size]\n",
        "\n",
        "                for j in range(TRAINING_RATIO):\n",
        "                    image_batch = discriminator_minibatches[j * BATCHSIZE : (j + 1) * BATCHSIZE]\n",
        "                    noise = np.random.randn(BATCHSIZE, 128).astype(np.float32)\n",
        "                    discriminator.trainable = True\n",
        "                    generator.trainable = False\n",
        "                    discriminator_loss.append(model_for_training_discriminator.train_on_batch([image_batch, noise],\n",
        "                                                                                              [real_y, fake_y, dummy_y]))\n",
        "                discriminator.trainable = False\n",
        "                generator.trainable = True\n",
        "                generator_loss.append(model_for_training_generator.train_on_batch(np.random.randn(BATCHSIZE, 128), real_y))\n",
        "\n",
        "            print('\\nepoch time: {}'.format(time()-start_time))\n",
        "            #Generate image\n",
        "            generated_image = generator.predict(test_noise)\n",
        "            generated_image = (generated_image+1)/2\n",
        "            for i in range(GENERATE_ROW_NUM):\n",
        "                new = generated_image[i*GENERATE_ROW_NUM:i*GENERATE_ROW_NUM+GENERATE_ROW_NUM].reshape(32*GENERATE_ROW_NUM,32,3)\n",
        "                if i!=0:\n",
        "                    old = np.concatenate((old,new),axis=1)\n",
        "                else:\n",
        "                    old = new\n",
        "            print('plot generated_image')\n",
        "            plt.imsave('{}/epoch_{:03}.png'.format(SAVE_DIR, epoch), old)\n",
        "            \n",
        "            plt.plot(discriminator_loss)\n",
        "            plt.plot(generator_loss)\n",
        "            plt.legend(['discriminator', 'real_D_loss', 'fake_D_loss', 'GP_Loss', 'generator_loss'])\n",
        "            plt.savefig(SAVE_DIR+'/loss.png')\n",
        "            plt.clf()\n",
        "\n",
        "            pickle.dump({'discriminator_loss': discriminator_loss, \n",
        "                        'generator_loss': generator_loss}, \n",
        "                        open(SAVE_DIR+'/loss-history.pkl', 'wb'))\n",
        "\n",
        "\n",
        "    else:\n",
        "        for epoch in range(EPOCHS):\n",
        "            np.random.shuffle(X)\n",
        "\n",
        "            print(\"epoch {} of {}\".format(epoch+1, EPOCHS))\n",
        "            num_batches = int(X.shape[0] // BATCHSIZE)\n",
        "\n",
        "            print(\"number of batches: {}\".format(int(X.shape[0] // (BATCHSIZE))))\n",
        "\n",
        "            progress_bar = Progbar(target=int(X.shape[0] // (BATCHSIZE * TRAINING_RATIO)))\n",
        "            minibatches_size = BATCHSIZE * TRAINING_RATIO\n",
        "\n",
        "            start_time = time()\n",
        "            for index in range(int(X.shape[0] // (BATCHSIZE * TRAINING_RATIO))):\n",
        "                progress_bar.update(index)\n",
        "                discriminator_minibatches = X[index * minibatches_size:(index + 1) * minibatches_size]\n",
        "\n",
        "                for j in range(TRAINING_RATIO):\n",
        "                    image_batch = discriminator_minibatches[j * BATCHSIZE : (j + 1) * BATCHSIZE]\n",
        "                    noise = np.random.randn(BATCHSIZE, 128).astype(np.float32)\n",
        "                    discriminator.trainable = True\n",
        "                    generator.trainable = False\n",
        "                    discriminator_loss.append(model_for_training_discriminator.train_on_batch([image_batch, noise],\n",
        "                                                                                              [real_y, fake_y]))\n",
        "                discriminator.trainable = False\n",
        "                generator.trainable = True\n",
        "                generator_loss.append(model_for_training_generator.train_on_batch(np.random.randn(BATCHSIZE, 128), real_y))\n",
        "\n",
        "            print('\\nepoch time: {}'.format(time()-start_time))\n",
        "\n",
        "            #Generate image\n",
        "            generated_image = generator.predict(test_noise)\n",
        "            generated_image = (generated_image+1)/2\n",
        "            for i in range(GENERATE_ROW_NUM):\n",
        "                new = generated_image[i*GENERATE_ROW_NUM:i*GENERATE_ROW_NUM+GENERATE_ROW_NUM].reshape(32*GENERATE_ROW_NUM,32,3)\n",
        "                if i!=0:\n",
        "                    old = np.concatenate((old,new),axis=1)\n",
        "                else:\n",
        "                    old = new\n",
        "            print('plot generated_image')\n",
        "            plt.imsave('{}/epoch_{:03}.png'.format(SAVE_DIR, epoch), old)\n",
        "            \n",
        "            plt.plot(discriminator_loss)\n",
        "            plt.plot(generator_loss)\n",
        "            plt.legend(['discriminator', 'real_D_loss', 'fake_D_loss', 'generator_loss'])\n",
        "            plt.savefig(SAVE_DIR+'/loss.png')\n",
        "            plt.clf()\n",
        "\n",
        "            pickle.dump({'discriminator_loss': discriminator_loss, \n",
        "                        'generator_loss': generator_loss}, \n",
        "                        open(SAVE_DIR+'/loss-history.pkl', 'wb'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-9416b06d478e>\"\u001b[0;36m, line \u001b[0;32m689\u001b[0m\n\u001b[0;31m    def ResBlock(input_shape, sampling=None, trainable_sortcut=True,\u001b[0m\n\u001b[0m                                                                     ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96T7phFQslqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}